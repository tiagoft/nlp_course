{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Models: the XX-Century approach\n",
    "\n",
    "So far, we have used probabilistic models to determine the likelihood of finding a word $w$ in any document within the collection $c$, that is: $P(w | c)$. Implicitly, this means that the order of words within a document does not impact its meaning. Metaphorically, it's as if we placed all the words in a big bag, and therefore this type of representation based on the presence or absence of words is called a bag-of-words.\n",
    "\n",
    "The bag-of-words model is effective for many applications but can miss important characteristics of a word: on the one hand, it is unlikely that a text mentioning \"platypuses\" and \"kangaroos\" is not referring to both; on the other hand, the text: \"platypuses are more dangerous than kangaroos\" is very different from \"kangaroos are more dangerous than platypuses\".\n",
    "\n",
    "One way to create models for the order in which words appear in a text is called a generative linguistic model (or generative, depending on the translation you adopt). In this type of model, we estimate the probability of finding the $n$-th word of a sequence based on the previous word, that is:\n",
    "\n",
    "$ùëÉ(ùë§_ùëõ‚à£ùë§_{ùëõ‚àí1})$\n",
    "\n",
    "We can create a small model for the phrase:\n",
    "\n",
    "Pass one, pass two, pass three\n",
    "\n",
    "In this case, our model gives us probabilities like:\n",
    "\n",
    "$P(\\text{pass} | \\text{one}) = 1$\n",
    "\n",
    "$P(\\text{pass} | \\text{two}) = 1$\n",
    "\n",
    "$P(\\text{two} | \\text{pass}) = 1/3$\n",
    "\n",
    "Note that these probabilities are estimated by counting in a training data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: conditional probabilities for next word\n",
    "\n",
    "In the excerpt below:\n",
    "\n",
    "Joana went for a walk with some of her seven dogs on a sunny afternoon, and she met a friend. A person who was there also stopped to talk to them, and some other dogs also stopped to play with the dogs.\n",
    "\n",
    "Calculate:\n",
    "\n",
    "* $P(\\text{afternoon} | \\text{sunny})$\n",
    "* $P(\\text{some} | \\text{with})$\n",
    "* $P(\\text{on} | \\text{dogs})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: estimating a linguistic model\n",
    "\n",
    "There are many libraries that can be used to estimate the conditional probabilities for all words in a text. We are going to build these probabilities from scratch.\n",
    "\n",
    "The piece of code below splits a text into its individual words (we are not concerned with punctuation at this point).\n",
    "\n",
    "Add to the code so that we generate a \"dictionary of dictionaries\", similar to an inverted index. This structure must represent conditional probabilities in the following way:\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "* $P(\\text{dogs} | \\text{with}) = 0.2$\n",
    "* $P(\\text{dogs} | \\text{her}) = 0.3$\n",
    "* $P(\\text{cats} | \\text{her}) = 0.4$\n",
    "\n",
    "the data structure should look like:\n",
    "\n",
    "    {\n",
    "        'with' : { 'dogs' : 0.2 },\n",
    "        'her' : { 'dogs' : 0.3,\n",
    "                  'cats' : 0.4}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NATURAL', 'LANGUAGE', 'PROCESSING', 'NLP', 'IS', 'A', 'SUBFIELD', 'OF', 'LINGUISTICS', 'COMPUTER', 'SCIENCE', 'INFORMATION', 'ENGINEERING', 'AND', 'ARTIFICIAL', 'INTELLIGENCE', 'CONCERNED', 'WITH', 'THE', 'INTERACTIONS', 'BETWEEN', 'COMPUTERS', 'AND', 'HUMAN', 'NATURAL', 'LANGUAGES', 'IN', 'PARTICULAR', 'HOW', 'TO', 'PROGRAM', 'COMPUTERS', 'TO', 'PROCESS', 'AND', 'ANALYZE', 'LARGE', 'AMOUNTS', 'OF', 'NATURAL', 'LANGUAGE', 'DATA', 'CHALLENGES', 'IN', 'NATURAL', 'LANGUAGE', 'PROCESSING', 'FREQUENTLY', 'INVOLVE', 'SPEECH', 'RECOGNITION', 'NATURAL', 'LANGUAGE', 'UNDERSTANDING', 'AND', 'NATURAL', 'LANGUAGE', 'GENERATION', 'NOWADAYS', 'ARTIFICIAL', 'INTELLIGENCE', 'IS', 'A', 'HIGHLY', 'TRENDING', 'TECHNOLOGY', 'AND', 'IS', 'GAINING', 'POPULARITY', 'AMONG', 'NLP', 'DEVELOPERS', 'ALTHOUGH', 'ARTIFICIAL', 'INTELLIGENCE', 'IS', 'A', 'MARVELOUS', 'TECHNOLOGY', 'AND', 'HAS', 'WONDERFUL', 'RESULTS', 'IT', 'IS', 'STILL', 'A', 'DEVELOPING', 'TECHNOLOGY', 'AND', 'ITS', 'ETHICAL', 'USE', 'IS', 'A', 'MAJOR', 'CONCERN']\n",
      "{'LARGE': defaultdict(<class 'int'>, {}), 'HIGHLY': defaultdict(<class 'int'>, {}), 'PROGRAM': defaultdict(<class 'int'>, {}), 'DEVELOPING': defaultdict(<class 'int'>, {}), 'ITS': defaultdict(<class 'int'>, {}), 'MAJOR': defaultdict(<class 'int'>, {}), 'AMONG': defaultdict(<class 'int'>, {}), 'COMPUTERS': defaultdict(<class 'int'>, {}), 'MARVELOUS': defaultdict(<class 'int'>, {}), 'CHALLENGES': defaultdict(<class 'int'>, {}), 'PROCESSING': defaultdict(<class 'int'>, {}), 'NATURAL': defaultdict(<class 'int'>, {}), 'ARTIFICIAL': defaultdict(<class 'int'>, {}), 'IN': defaultdict(<class 'int'>, {}), 'TRENDING': defaultdict(<class 'int'>, {}), 'GENERATION': defaultdict(<class 'int'>, {}), 'STILL': defaultdict(<class 'int'>, {}), 'WITH': defaultdict(<class 'int'>, {}), 'AMOUNTS': defaultdict(<class 'int'>, {}), 'IS': defaultdict(<class 'int'>, {}), 'FREQUENTLY': defaultdict(<class 'int'>, {}), 'UNDERSTANDING': defaultdict(<class 'int'>, {}), 'NLP': defaultdict(<class 'int'>, {}), 'TECHNOLOGY': defaultdict(<class 'int'>, {}), 'RESULTS': defaultdict(<class 'int'>, {}), 'USE': defaultdict(<class 'int'>, {}), 'HAS': defaultdict(<class 'int'>, {}), 'INFORMATION': defaultdict(<class 'int'>, {}), 'INTERACTIONS': defaultdict(<class 'int'>, {}), 'RECOGNITION': defaultdict(<class 'int'>, {}), 'ETHICAL': defaultdict(<class 'int'>, {}), 'WONDERFUL': defaultdict(<class 'int'>, {}), 'THE': defaultdict(<class 'int'>, {}), 'IT': defaultdict(<class 'int'>, {}), 'INTELLIGENCE': defaultdict(<class 'int'>, {}), 'TO': defaultdict(<class 'int'>, {}), 'AND': defaultdict(<class 'int'>, {}), 'COMPUTER': defaultdict(<class 'int'>, {}), 'POPULARITY': defaultdict(<class 'int'>, {}), 'SUBFIELD': defaultdict(<class 'int'>, {}), 'CONCERNED': defaultdict(<class 'int'>, {}), 'PROCESS': defaultdict(<class 'int'>, {}), 'HOW': defaultdict(<class 'int'>, {}), 'GAINING': defaultdict(<class 'int'>, {}), 'DATA': defaultdict(<class 'int'>, {}), 'SCIENCE': defaultdict(<class 'int'>, {}), 'ANALYZE': defaultdict(<class 'int'>, {}), 'CONCERN': defaultdict(<class 'int'>, {}), 'BETWEEN': defaultdict(<class 'int'>, {}), 'LANGUAGES': defaultdict(<class 'int'>, {}), 'PARTICULAR': defaultdict(<class 'int'>, {}), 'INVOLVE': defaultdict(<class 'int'>, {}), 'ALTHOUGH': defaultdict(<class 'int'>, {}), 'LANGUAGE': defaultdict(<class 'int'>, {}), 'OF': defaultdict(<class 'int'>, {}), 'DEVELOPERS': defaultdict(<class 'int'>, {}), 'LINGUISTICS': defaultdict(<class 'int'>, {}), 'HUMAN': defaultdict(<class 'int'>, {}), 'NOWADAYS': defaultdict(<class 'int'>, {}), 'A': defaultdict(<class 'int'>, {}), 'ENGINEERING': defaultdict(<class 'int'>, {}), 'SPEECH': defaultdict(<class 'int'>, {})}\n",
      "{'LARGE': defaultdict(<class 'int'>, {'AMOUNTS': 1}), 'HIGHLY': defaultdict(<class 'int'>, {'TRENDING': 1}), 'PROGRAM': defaultdict(<class 'int'>, {'COMPUTERS': 1}), 'DEVELOPING': defaultdict(<class 'int'>, {'TECHNOLOGY': 1}), 'ITS': defaultdict(<class 'int'>, {'ETHICAL': 1}), 'MAJOR': defaultdict(<class 'int'>, {'CONCERN': 1}), 'AMONG': defaultdict(<class 'int'>, {'NLP': 1}), 'COMPUTERS': defaultdict(<class 'int'>, {'AND': 1, 'TO': 1}), 'MARVELOUS': defaultdict(<class 'int'>, {'TECHNOLOGY': 1}), 'CHALLENGES': defaultdict(<class 'int'>, {'IN': 1}), 'PROCESSING': defaultdict(<class 'int'>, {'NLP': 1, 'FREQUENTLY': 1}), 'NATURAL': defaultdict(<class 'int'>, {'LANGUAGE': 5, 'LANGUAGES': 1}), 'ARTIFICIAL': defaultdict(<class 'int'>, {'INTELLIGENCE': 3}), 'IN': defaultdict(<class 'int'>, {'PARTICULAR': 1, 'NATURAL': 1}), 'TRENDING': defaultdict(<class 'int'>, {'TECHNOLOGY': 1}), 'GENERATION': defaultdict(<class 'int'>, {'NOWADAYS': 1}), 'STILL': defaultdict(<class 'int'>, {'A': 1}), 'WITH': defaultdict(<class 'int'>, {'THE': 1}), 'AMOUNTS': defaultdict(<class 'int'>, {'OF': 1}), 'IS': defaultdict(<class 'int'>, {'A': 4, 'GAINING': 1, 'STILL': 1}), 'FREQUENTLY': defaultdict(<class 'int'>, {'INVOLVE': 1}), 'UNDERSTANDING': defaultdict(<class 'int'>, {'AND': 1}), 'NLP': defaultdict(<class 'int'>, {'IS': 1, 'DEVELOPERS': 1}), 'TECHNOLOGY': defaultdict(<class 'int'>, {'AND': 3}), 'RESULTS': defaultdict(<class 'int'>, {'IT': 1}), 'USE': defaultdict(<class 'int'>, {'IS': 1}), 'HAS': defaultdict(<class 'int'>, {'WONDERFUL': 1}), 'INFORMATION': defaultdict(<class 'int'>, {'ENGINEERING': 1}), 'INTERACTIONS': defaultdict(<class 'int'>, {'BETWEEN': 1}), 'RECOGNITION': defaultdict(<class 'int'>, {'NATURAL': 1}), 'ETHICAL': defaultdict(<class 'int'>, {'USE': 1}), 'WONDERFUL': defaultdict(<class 'int'>, {'RESULTS': 1}), 'THE': defaultdict(<class 'int'>, {'INTERACTIONS': 1}), 'IT': defaultdict(<class 'int'>, {'IS': 1}), 'INTELLIGENCE': defaultdict(<class 'int'>, {'CONCERNED': 1, 'IS': 2}), 'TO': defaultdict(<class 'int'>, {'PROGRAM': 1, 'PROCESS': 1}), 'AND': defaultdict(<class 'int'>, {'ARTIFICIAL': 1, 'HUMAN': 1, 'ANALYZE': 1, 'NATURAL': 1, 'IS': 1, 'HAS': 1, 'ITS': 1}), 'COMPUTER': defaultdict(<class 'int'>, {'SCIENCE': 1}), 'POPULARITY': defaultdict(<class 'int'>, {'AMONG': 1}), 'SUBFIELD': defaultdict(<class 'int'>, {'OF': 1}), 'CONCERNED': defaultdict(<class 'int'>, {'WITH': 1}), 'PROCESS': defaultdict(<class 'int'>, {'AND': 1}), 'HOW': defaultdict(<class 'int'>, {'TO': 1}), 'GAINING': defaultdict(<class 'int'>, {'POPULARITY': 1}), 'DATA': defaultdict(<class 'int'>, {'CHALLENGES': 1}), 'SCIENCE': defaultdict(<class 'int'>, {'INFORMATION': 1}), 'ANALYZE': defaultdict(<class 'int'>, {'LARGE': 1}), 'CONCERN': defaultdict(<class 'int'>, {}), 'BETWEEN': defaultdict(<class 'int'>, {'COMPUTERS': 1}), 'LANGUAGES': defaultdict(<class 'int'>, {'IN': 1}), 'PARTICULAR': defaultdict(<class 'int'>, {'HOW': 1}), 'INVOLVE': defaultdict(<class 'int'>, {'SPEECH': 1}), 'ALTHOUGH': defaultdict(<class 'int'>, {'ARTIFICIAL': 1}), 'LANGUAGE': defaultdict(<class 'int'>, {'PROCESSING': 2, 'DATA': 1, 'UNDERSTANDING': 1, 'GENERATION': 1}), 'OF': defaultdict(<class 'int'>, {'LINGUISTICS': 1, 'NATURAL': 1}), 'DEVELOPERS': defaultdict(<class 'int'>, {'ALTHOUGH': 1}), 'LINGUISTICS': defaultdict(<class 'int'>, {'COMPUTER': 1}), 'HUMAN': defaultdict(<class 'int'>, {'NATURAL': 1}), 'NOWADAYS': defaultdict(<class 'int'>, {'ARTIFICIAL': 1}), 'A': defaultdict(<class 'int'>, {'SUBFIELD': 1, 'HIGHLY': 1, 'MARVELOUS': 1, 'DEVELOPING': 1, 'MAJOR': 1}), 'ENGINEERING': defaultdict(<class 'int'>, {'AND': 1}), 'SPEECH': defaultdict(<class 'int'>, {'RECOGNITION': 1})}\n",
      "{'A': defaultdict(<class 'int'>,\n",
      "                  {'DEVELOPING': 0.2,\n",
      "                   'HIGHLY': 0.2,\n",
      "                   'MAJOR': 0.2,\n",
      "                   'MARVELOUS': 0.2,\n",
      "                   'SUBFIELD': 0.2}),\n",
      " 'ALTHOUGH': defaultdict(<class 'int'>, {'ARTIFICIAL': 1.0}),\n",
      " 'AMONG': defaultdict(<class 'int'>, {'NLP': 1.0}),\n",
      " 'AMOUNTS': defaultdict(<class 'int'>, {'OF': 1.0}),\n",
      " 'ANALYZE': defaultdict(<class 'int'>, {'LARGE': 1.0}),\n",
      " 'AND': defaultdict(<class 'int'>,\n",
      "                    {'ANALYZE': 0.14285714285714285,\n",
      "                     'ARTIFICIAL': 0.14285714285714285,\n",
      "                     'HAS': 0.14285714285714285,\n",
      "                     'HUMAN': 0.14285714285714285,\n",
      "                     'IS': 0.14285714285714285,\n",
      "                     'ITS': 0.14285714285714285,\n",
      "                     'NATURAL': 0.14285714285714285}),\n",
      " 'ARTIFICIAL': defaultdict(<class 'int'>, {'INTELLIGENCE': 1.0}),\n",
      " 'BETWEEN': defaultdict(<class 'int'>, {'COMPUTERS': 1.0}),\n",
      " 'CHALLENGES': defaultdict(<class 'int'>, {'IN': 1.0}),\n",
      " 'COMPUTER': defaultdict(<class 'int'>, {'SCIENCE': 1.0}),\n",
      " 'COMPUTERS': defaultdict(<class 'int'>, {'AND': 0.5, 'TO': 0.5}),\n",
      " 'CONCERN': defaultdict(<class 'int'>, {}),\n",
      " 'CONCERNED': defaultdict(<class 'int'>, {'WITH': 1.0}),\n",
      " 'DATA': defaultdict(<class 'int'>, {'CHALLENGES': 1.0}),\n",
      " 'DEVELOPERS': defaultdict(<class 'int'>, {'ALTHOUGH': 1.0}),\n",
      " 'DEVELOPING': defaultdict(<class 'int'>, {'TECHNOLOGY': 1.0}),\n",
      " 'ENGINEERING': defaultdict(<class 'int'>, {'AND': 1.0}),\n",
      " 'ETHICAL': defaultdict(<class 'int'>, {'USE': 1.0}),\n",
      " 'FREQUENTLY': defaultdict(<class 'int'>, {'INVOLVE': 1.0}),\n",
      " 'GAINING': defaultdict(<class 'int'>, {'POPULARITY': 1.0}),\n",
      " 'GENERATION': defaultdict(<class 'int'>, {'NOWADAYS': 1.0}),\n",
      " 'HAS': defaultdict(<class 'int'>, {'WONDERFUL': 1.0}),\n",
      " 'HIGHLY': defaultdict(<class 'int'>, {'TRENDING': 1.0}),\n",
      " 'HOW': defaultdict(<class 'int'>, {'TO': 1.0}),\n",
      " 'HUMAN': defaultdict(<class 'int'>, {'NATURAL': 1.0}),\n",
      " 'IN': defaultdict(<class 'int'>, {'PARTICULAR': 0.5, 'NATURAL': 0.5}),\n",
      " 'INFORMATION': defaultdict(<class 'int'>, {'ENGINEERING': 1.0}),\n",
      " 'INTELLIGENCE': defaultdict(<class 'int'>,\n",
      "                             {'CONCERNED': 0.3333333333333333,\n",
      "                              'IS': 0.6666666666666666}),\n",
      " 'INTERACTIONS': defaultdict(<class 'int'>, {'BETWEEN': 1.0}),\n",
      " 'INVOLVE': defaultdict(<class 'int'>, {'SPEECH': 1.0}),\n",
      " 'IS': defaultdict(<class 'int'>,\n",
      "                   {'A': 0.6666666666666666,\n",
      "                    'GAINING': 0.16666666666666666,\n",
      "                    'STILL': 0.16666666666666666}),\n",
      " 'IT': defaultdict(<class 'int'>, {'IS': 1.0}),\n",
      " 'ITS': defaultdict(<class 'int'>, {'ETHICAL': 1.0}),\n",
      " 'LANGUAGE': defaultdict(<class 'int'>,\n",
      "                         {'DATA': 0.2,\n",
      "                          'GENERATION': 0.2,\n",
      "                          'PROCESSING': 0.4,\n",
      "                          'UNDERSTANDING': 0.2}),\n",
      " 'LANGUAGES': defaultdict(<class 'int'>, {'IN': 1.0}),\n",
      " 'LARGE': defaultdict(<class 'int'>, {'AMOUNTS': 1.0}),\n",
      " 'LINGUISTICS': defaultdict(<class 'int'>, {'COMPUTER': 1.0}),\n",
      " 'MAJOR': defaultdict(<class 'int'>, {'CONCERN': 1.0}),\n",
      " 'MARVELOUS': defaultdict(<class 'int'>, {'TECHNOLOGY': 1.0}),\n",
      " 'NATURAL': defaultdict(<class 'int'>,\n",
      "                        {'LANGUAGE': 0.8333333333333334,\n",
      "                         'LANGUAGES': 0.16666666666666666}),\n",
      " 'NLP': defaultdict(<class 'int'>, {'IS': 0.5, 'DEVELOPERS': 0.5}),\n",
      " 'NOWADAYS': defaultdict(<class 'int'>, {'ARTIFICIAL': 1.0}),\n",
      " 'OF': defaultdict(<class 'int'>, {'LINGUISTICS': 0.5, 'NATURAL': 0.5}),\n",
      " 'PARTICULAR': defaultdict(<class 'int'>, {'HOW': 1.0}),\n",
      " 'POPULARITY': defaultdict(<class 'int'>, {'AMONG': 1.0}),\n",
      " 'PROCESS': defaultdict(<class 'int'>, {'AND': 1.0}),\n",
      " 'PROCESSING': defaultdict(<class 'int'>, {'NLP': 0.5, 'FREQUENTLY': 0.5}),\n",
      " 'PROGRAM': defaultdict(<class 'int'>, {'COMPUTERS': 1.0}),\n",
      " 'RECOGNITION': defaultdict(<class 'int'>, {'NATURAL': 1.0}),\n",
      " 'RESULTS': defaultdict(<class 'int'>, {'IT': 1.0}),\n",
      " 'SCIENCE': defaultdict(<class 'int'>, {'INFORMATION': 1.0}),\n",
      " 'SPEECH': defaultdict(<class 'int'>, {'RECOGNITION': 1.0}),\n",
      " 'STILL': defaultdict(<class 'int'>, {'A': 1.0}),\n",
      " 'SUBFIELD': defaultdict(<class 'int'>, {'OF': 1.0}),\n",
      " 'TECHNOLOGY': defaultdict(<class 'int'>, {'AND': 1.0}),\n",
      " 'THE': defaultdict(<class 'int'>, {'INTERACTIONS': 1.0}),\n",
      " 'TO': defaultdict(<class 'int'>, {'PROGRAM': 0.5, 'PROCESS': 0.5}),\n",
      " 'TRENDING': defaultdict(<class 'int'>, {'TECHNOLOGY': 1.0}),\n",
      " 'UNDERSTANDING': defaultdict(<class 'int'>, {'AND': 1.0}),\n",
      " 'USE': defaultdict(<class 'int'>, {'IS': 1.0}),\n",
      " 'WITH': defaultdict(<class 'int'>, {'THE': 1.0}),\n",
      " 'WONDERFUL': defaultdict(<class 'int'>, {'RESULTS': 1.0})}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence\n",
    "concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze\n",
    "large amounts of natural language data.\n",
    "Challenges in natural language processing frequently involve speech recognition, natural language understanding,\n",
    "and natural language generation. Nowadays, Artificial Intelligence is a highly trending technology and is gaining popularity among NLP developers.\n",
    "Although Artificial Intelligence is a marvelous technology and has wonderful results, it is still a developing technology and its ethical use is a major concern.\n",
    "\"\"\"\n",
    "\n",
    "words = re.findall(r\"\\b\\w+\\b\", text.upper())\n",
    "print(words)\n",
    "\n",
    "from collections import defaultdict\n",
    "vocab = set(words)\n",
    "conditional_probabilities = {}\n",
    "for v in vocab:\n",
    "    conditional_probabilities[v] = defaultdict(int)\n",
    "\n",
    "print(conditional_probabilities)\n",
    "\n",
    "for idx,w in enumerate(words[:-1]):\n",
    "    conditional_probabilities[w][words[idx+1]] += 1\n",
    "\n",
    "print(conditional_probabilities)\n",
    "\n",
    "for previous_word in conditional_probabilities.keys():\n",
    "    total = sum(conditional_probabilities[previous_word].values())\n",
    "    for next_word in conditional_probabilities[previous_word].keys():\n",
    "        conditional_probabilities[previous_word][next_word] /= total\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(conditional_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conditional_probabilities.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use the code below to test your solution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loaded_conditional_probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconditional_probabilities.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (conditional_probabilities \u001b[38;5;241m==\u001b[39m loaded_conditional_probabilities)\n",
      "File \u001b[0;32m~/Desktop/nlp_course/env/lib/python3.12/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conditional_probabilities.joblib'"
     ]
    }
   ],
   "source": [
    "# Use the code below to test your solution\n",
    "import joblib\n",
    "loaded_conditional_probabilities = joblib.load(\"conditional_probabilities.joblib\")\n",
    "print (conditional_probabilities == loaded_conditional_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: suggest a next word\n",
    "\n",
    "Based on the model estimated in the previous exercise, program a function that takes a word and returns a possible next word. If the base word is not part of the model's vocabulary, it should return a random word from the vocabulary. Use the `np.random.choice` functionality to make choices with predefined probabilities, as shown below. Remember that you should use the probabilities calculated by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('LANGUAGES')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_next_word(conditional_probabilities, palavra_atual):\n",
    "    palavras = list(conditional_probabilities[palavra_atual].keys())\n",
    "    probs = []\n",
    "    for palavra in palavras:\n",
    "        probs.append(conditional_probabilities[palavra_atual][palavra])\n",
    "    # palavras, probs = zip(*conditional_probabilities[palavra_atual].items())\n",
    "    return np.random.choice(palavras, p=probs)\n",
    "\n",
    "\n",
    "generate_next_word(conditional_probabilities, \"NATURAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: make a text generator\n",
    "\n",
    "Use the functionality you implemented above to suggest next words, and then incorporate them into your text. For example:\n",
    "\n",
    "1. Start with \"artificial intelligence is\"\n",
    "1. Suggest word \"a\"\n",
    "1. Incorporate \"a\" into the original sentence, so that we have: \"artificial intelligence is a\"\n",
    "1. Suggest next word based on \"artificial intelligence is a\"\n",
    "1. Keep going!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFICIAL INTELLIGENCE IS STILL A HIGHLY TRENDING TECHNOLOGY AND ARTIFICIAL INTELLIGENCE IS GAINING POPULARITY AMONG NLP DEVELOPERS ALTHOUGH ARTIFICIAL INTELLIGENCE CONCERNED WITH THE INTERACTIONS BETWEEN COMPUTERS AND ANALYZE LARGE AMOUNTS OF NATURAL LANGUAGE DATA CHALLENGES IN NATURAL LANGUAGE PROCESSING FREQUENTLY INVOLVE SPEECH RECOGNITION NATURAL LANGUAGES IN NATURAL LANGUAGE UNDERSTANDING AND NATURAL LANGUAGE PROCESSING NLP DEVELOPERS ALTHOUGH ARTIFICIAL INTELLIGENCE IS A MARVELOUS TECHNOLOGY AND IS STILL A DEVELOPING TECHNOLOGY AND ITS ETHICAL USE IS STILL A DEVELOPING TECHNOLOGY AND HUMAN NATURAL LANGUAGE PROCESSING NLP IS A SUBFIELD OF NATURAL LANGUAGES IN NATURAL LANGUAGE DATA CHALLENGES IN PARTICULAR HOW TO PROCESS AND ITS ETHICAL USE\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model : dict, starting_string : str, num_words : int) -> str:\n",
    "    text = starting_string\n",
    "    # Generate words based on your model (model should be the conditional probabilities!)\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        next_word = generate_next_word(model, text.split()[-1])\n",
    "        text += \" \" + next_word\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "print(generate_text(conditional_probabilities, \"ARTIFICIAL INTELLIGENCE IS\", 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: use n-grams\n",
    "\n",
    "By now, you might have noticed that using one single word in the past to predict the next word feels wrong. This is because we choose words based on a long-term context - and using a single word is a large oversimplification on this.\n",
    "\n",
    "A possible solution is to change our original equation $ùëÉ(ùë§_ùëõ‚à£ùë§_{ùëõ‚àí1})$ to a less naive one in which the probability of a word is calculated based on $L$ previous words ($L$ stands for \"context length\"): $ùëÉ(ùë§_ùëõ‚à£ùë§_{ùëõ‚àí1}, w_{n-2}, \\cdots, w_{n-L})$ . For such, we will need to use n-grams.\n",
    "\n",
    "N-grams are simply sequences of N words that appear in the text. For example, in \"these are nice n-grams\", for n=2, we have the n-grams: \"these are\", \"are nice\", \"nice n-grams\". Note that now we can calculate $P(\\text{nice}|\\text{these are}).\n",
    "\n",
    "Based on the code below, change your code to find conditional probabilities so now we have a data structure that models $ùëÉ(ùë§_ùëõ‚à£ùë§_{ùëõ‚àí1}, w_{n-2}, \\cdots, w_{n-L})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NATURAL', 'LANGUAGE', 'PROCESSING'), ('LANGUAGE', 'PROCESSING', 'NLP'), ('PROCESSING', 'NLP', 'IS'), ('NLP', 'IS', 'A'), ('IS', 'A', 'SUBFIELD'), ('A', 'SUBFIELD', 'OF'), ('SUBFIELD', 'OF', 'LINGUISTICS'), ('OF', 'LINGUISTICS', 'COMPUTER'), ('LINGUISTICS', 'COMPUTER', 'SCIENCE'), ('COMPUTER', 'SCIENCE', 'INFORMATION'), ('SCIENCE', 'INFORMATION', 'ENGINEERING'), ('INFORMATION', 'ENGINEERING', 'AND'), ('ENGINEERING', 'AND', 'ARTIFICIAL'), ('AND', 'ARTIFICIAL', 'INTELLIGENCE'), ('ARTIFICIAL', 'INTELLIGENCE', 'CONCERNED'), ('INTELLIGENCE', 'CONCERNED', 'WITH'), ('CONCERNED', 'WITH', 'THE'), ('WITH', 'THE', 'INTERACTIONS'), ('THE', 'INTERACTIONS', 'BETWEEN'), ('INTERACTIONS', 'BETWEEN', 'COMPUTERS'), ('BETWEEN', 'COMPUTERS', 'AND'), ('COMPUTERS', 'AND', 'HUMAN'), ('AND', 'HUMAN', 'NATURAL'), ('HUMAN', 'NATURAL', 'LANGUAGES'), ('NATURAL', 'LANGUAGES', 'IN'), ('LANGUAGES', 'IN', 'PARTICULAR'), ('IN', 'PARTICULAR', 'HOW'), ('PARTICULAR', 'HOW', 'TO'), ('HOW', 'TO', 'PROGRAM'), ('TO', 'PROGRAM', 'COMPUTERS'), ('PROGRAM', 'COMPUTERS', 'TO'), ('COMPUTERS', 'TO', 'PROCESS'), ('TO', 'PROCESS', 'AND'), ('PROCESS', 'AND', 'ANALYZE'), ('AND', 'ANALYZE', 'LARGE'), ('ANALYZE', 'LARGE', 'AMOUNTS'), ('LARGE', 'AMOUNTS', 'OF'), ('AMOUNTS', 'OF', 'NATURAL'), ('OF', 'NATURAL', 'LANGUAGE'), ('NATURAL', 'LANGUAGE', 'DATA'), ('LANGUAGE', 'DATA', 'CHALLENGES'), ('DATA', 'CHALLENGES', 'IN'), ('CHALLENGES', 'IN', 'NATURAL'), ('IN', 'NATURAL', 'LANGUAGE'), ('NATURAL', 'LANGUAGE', 'PROCESSING'), ('LANGUAGE', 'PROCESSING', 'FREQUENTLY'), ('PROCESSING', 'FREQUENTLY', 'INVOLVE'), ('FREQUENTLY', 'INVOLVE', 'SPEECH'), ('INVOLVE', 'SPEECH', 'RECOGNITION'), ('SPEECH', 'RECOGNITION', 'NATURAL'), ('RECOGNITION', 'NATURAL', 'LANGUAGE'), ('NATURAL', 'LANGUAGE', 'UNDERSTANDING'), ('LANGUAGE', 'UNDERSTANDING', 'AND'), ('UNDERSTANDING', 'AND', 'NATURAL'), ('AND', 'NATURAL', 'LANGUAGE'), ('NATURAL', 'LANGUAGE', 'GENERATION'), ('LANGUAGE', 'GENERATION', 'NOWADAYS'), ('GENERATION', 'NOWADAYS', 'ARTIFICIAL'), ('NOWADAYS', 'ARTIFICIAL', 'INTELLIGENCE'), ('ARTIFICIAL', 'INTELLIGENCE', 'IS'), ('INTELLIGENCE', 'IS', 'A'), ('IS', 'A', 'HIGHLY'), ('A', 'HIGHLY', 'TRENDING'), ('HIGHLY', 'TRENDING', 'TECHNOLOGY'), ('TRENDING', 'TECHNOLOGY', 'AND'), ('TECHNOLOGY', 'AND', 'IS'), ('AND', 'IS', 'GAINING'), ('IS', 'GAINING', 'POPULARITY'), ('GAINING', 'POPULARITY', 'AMONG'), ('POPULARITY', 'AMONG', 'NLP'), ('AMONG', 'NLP', 'DEVELOPERS'), ('NLP', 'DEVELOPERS', 'ALTHOUGH'), ('DEVELOPERS', 'ALTHOUGH', 'ARTIFICIAL'), ('ALTHOUGH', 'ARTIFICIAL', 'INTELLIGENCE'), ('ARTIFICIAL', 'INTELLIGENCE', 'IS'), ('INTELLIGENCE', 'IS', 'A'), ('IS', 'A', 'MARVELOUS'), ('A', 'MARVELOUS', 'TECHNOLOGY'), ('MARVELOUS', 'TECHNOLOGY', 'AND'), ('TECHNOLOGY', 'AND', 'HAS'), ('AND', 'HAS', 'WONDERFUL'), ('HAS', 'WONDERFUL', 'RESULTS'), ('WONDERFUL', 'RESULTS', 'IT'), ('RESULTS', 'IT', 'IS'), ('IT', 'IS', 'STILL'), ('IS', 'STILL', 'A'), ('STILL', 'A', 'DEVELOPING'), ('A', 'DEVELOPING', 'TECHNOLOGY'), ('DEVELOPING', 'TECHNOLOGY', 'AND'), ('TECHNOLOGY', 'AND', 'ITS'), ('AND', 'ITS', 'ETHICAL'), ('ITS', 'ETHICAL', 'USE'), ('ETHICAL', 'USE', 'IS'), ('USE', 'IS', 'A'), ('IS', 'A', 'MAJOR')]\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(words : list, L : int) -> list:\n",
    "    ngrams = [tuple(words[i:i+L]) for i in range(len(words)-L)]\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: a fallback strategy\n",
    "\n",
    "Also, by now, you probably found out that larger n-grams become more and more uncommon. This is so true that finding two texts that contain n-grams with a context $L$ larger than around 10 can be used as basis to flag copy-paste plagiarism. Hence, with larger n-grams, we will probably fall into situations in which we don't have information on how to proceed.\n",
    "\n",
    "On the other hand, we might like larger context lengths because they can make our texts more cohesive.\n",
    "\n",
    "How to deal with that?\n",
    "\n",
    "One possibility is to have a weighting strategy in which the probabilities for models that consider different n-gram lengths are combined. However, the optimal combination could be hard to obtain.\n",
    "\n",
    "Another possibility is to use a fallback strategy: we try a model with context $L$. If it fails to find the n-gram, then we proceed to a model with context $L-1$, and so on.\n",
    "\n",
    "Implement a system with a fallback strategy and train/test it in our original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: generation techniques\n",
    "\n",
    "At this point, we generate the \"next word\" in a sequence by sampling from a distribution measured from data. We can make some tweaks here to make our generated words more interesting.\n",
    "\n",
    "### Temperature\n",
    "\n",
    "One possibility is to use a parameter called *temperature*. The temperature parameter (often referred to as $\\tau$) is inspired in annealing processes. In this process, electrons in materias with high temperature jump more often, thus they can be found in a probability cloud with larger variance.\n",
    "\n",
    "When we use temperature, we sample from a distribution $P_z$ calculated by:\n",
    "\n",
    "$$P_z( A | B) =  \\frac{P( A | B) ^ {e^{-\\tau}}}{\\sum{P( A | B) ^ {e^{-\\tau}}}} $$\n",
    "\n",
    "Note that, in this equation, a high temperature $(\\tau \\rightarrow \\infty)$ leads $P_z(A|B)$ to become a uniform distribution, whereas low (negative) values make the distribution more spiky. \n",
    "\n",
    "Also, note that there are many formulations for temperature. I like this one because $\\tau=0$ implies in $P_z(A|B) = P(A|B)$, so we have an anchor point. Check the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.4 0.1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def apply_temperature(P, tau):\n",
    "    z =  P**(np.exp(-tau))\n",
    "    return z / np.sum(z)\n",
    "P = np.array([0.5, 0.4, 0.1])\n",
    "print(apply_temperature(P, 0))\n",
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.bar(range(3), apply_temperature(P, 0))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = 0')\n",
    "plt.subplot(1,3,3)\n",
    "plt.bar(range(3), apply_temperature(P, 2))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = 2')\n",
    "plt.subplot(1,3,1)\n",
    "plt.bar(range(3), apply_temperature(P, -2))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = -2')\n",
    "plt.suptitle('Higher temperature makes the distribution closer to uniform!')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K\n",
    "\n",
    "Top-K generation is another interesting technique that essentially means we select the top $K$ most likely words from the distribution and then sample from them using uniform probabilities. The choice of $K$ impacts the level of randomness in the generation, and this technique can avoid large deviations from a particular trail of thought.\n",
    "\n",
    "### Implementing temperature or top-k\n",
    "\n",
    "Implement either temperature or top-k generation in your word generation function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: reading from real data\n",
    "\n",
    "The code below loads The Complete Works of Shakespeare from Project Guttemberg. Use this text to train your model and check if you can generate some shakespeare-like texts using your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "def load_shakespeare():\n",
    "    \"\"\"Getting Shakespeare text from Project Gutenberg \"\"\"\n",
    "\n",
    "    def download_file():\n",
    "        url = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            raise FileNotFoundError(\"Failed to download file.\")\n",
    "        text = response.content.decode('utf-8')\n",
    "        start_index = text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
    "        end_index = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
    "        if start_index == -1 or end_index == -1:\n",
    "            raise ValueError(\"Failed to find the start \"\n",
    "                             \"or end of the book in the text.\")\n",
    "        text = text[start_index:end_index]\n",
    "        return text\n",
    "\n",
    "    filepath_shakespeare = Path(\"shakespeare.txt\")\n",
    "\n",
    "    if filepath_shakespeare.exists():\n",
    "        print(\"File already exists. Skipping download...\")\n",
    "        with open(filepath_shakespeare, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    else:\n",
    "        print(\"Downloading file...\")\n",
    "        text = download_file()\n",
    "        with open(filepath_shakespeare, 'w', encoding='utf-8') as file:\n",
    "            file.write(text)\n",
    "        print(\"Download complete and text should be in 'shakespeare.txt' file.\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Temperature and LLMs.\n",
    "\n",
    "Well here comes my usual text about \"everything is LLMs nowadays\". Let's try temperature experiments with LLMs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 (low temp):  In generative models, temperature controls the randomness of the output.  A temperature of 1.0 means the model uses its predicted probabilities directly, resulting in relatively predictable, high-probability outputs.  Lower temperatures (e.g., 0.2) make the model more deterministic, favoring the most likely next token or feature, leading to more focused, less creative results.  Higher temperatures (e.g., 1.5) increase randomness, making the model explore less probable options, resulting in more diverse and surprising, but potentially less coherent, outputs.  Essentially, temperature acts as a knob to balance between quality and creativity, allowing users to fine-tune the model's output to their needs.\n",
      "\n",
      "Response 2 (low temp):  In generative models, temperature controls the randomness of the output.  A temperature of 1.0 means the model samples directly from its learned probability distribution.  Higher temperatures (e.g., 1.5) increase randomness, leading to more creative, surprising, and potentially nonsensical outputs.  The model becomes more likely to sample from less probable tokens, exploring the less-likely parts of its learned distribution.  Lower temperatures (e.g., 0.5) decrease randomness, resulting in more focused, deterministic, and often more predictable outputs. The model favors high-probability tokens, leading to safer, more conventional results.  Essentially, temperature acts as a knob to balance creativity and coherence in the generated content.\n",
      "\n",
      "Response 3 (high temp):  In generative models, temperature controls the randomness of the model's output.  It's a hyperparameter that scales the logits (pre-probability scores) before they're converted into probabilities using a softmax function.\n",
      "\n",
      "A low temperature (e.g., 0.2) makes the probability distribution sharper, focusing on the most likely tokens. This results in more focused, deterministic outputs, often coherent but potentially less creative.\n",
      "\n",
      "A high temperature (e.g., 1.0 or higher) flattens the probability distribution, increasing the probability of less likely tokens. This leads to more diverse and surprising outputs, but it can also result in incoherent or nonsensical text.  Essentially, higher temperature makes the model more \"risky\" in its choices.  The optimal temperature depends on the specific application and desired level of creativity vs. coherence.\n",
      "\n",
      "Response 4 (high temp):  In generative models, temperature controls the randomness of the output.  It's a hyperparameter that scales the logits (pre-softmax probabilities) before the softmax function is applied.  A high temperature (e.g., >1) increases the probabilities of less likely tokens, leading to more diverse, creative, and potentially unexpected outputs ‚Äì but potentially also nonsensical ones. Conversely, a low temperature (e.g., <1) sharpens the probability distribution, making the model more confident and focused on the most likely tokens. This results in more predictable, focused, and coherent outputs, but can be less creative and risk overfitting to the training data. A temperature of 1 leaves the distribution unchanged.  Essentially, temperature balances between exploration and exploitation during generation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "GEMINI_API_KEY = \"AIzaSyDwrlDqPYMT0WDcWkQIw8tOmwX6R-lH-eM\" # Go to https://aistudio.google.com/ to get a key. DO NOT commit your key to the repository!\n",
    "\n",
    "# Start the use of the API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Make our prompt here\n",
    "prompt = f\"Explain how temperature works in generative models in less than 200 words.\"\n",
    "generation_config_low_temp = genai.GenerationConfig(\n",
    "    max_output_tokens=500,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "generation_config_high_temp = genai.GenerationConfig(\n",
    "    max_output_tokens=500,\n",
    "    temperature=2.0,\n",
    ")\n",
    "\n",
    "# Use our prompt four times\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=generation_config_low_temp)\n",
    "print(\"Response 1 (low temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=generation_config_low_temp)\n",
    "print(\"Response 2 (low temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=generation_config_high_temp)\n",
    "print(\"Response 3 (high temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=generation_config_high_temp)\n",
    "print(\"Response 4 (high temp): \", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we know how to configure temperature with LLMs - they are simply a parameter in the call!\n",
    "\n",
    "Go on your own now. Let's try some ideas:\n",
    "\n",
    "1. Ask the LLM to generate a paragraph in which a shakespearean hero finds out his beloved one is married to another man.\n",
    "1. Intentionally describe the character in a bit more detail\n",
    "1. Insert the initial part of Shakespeare's Complete Works as part of the prompt, so that the system copies Shakespeare's style.\n",
    "1. Adjust the temperature parameter in the cases above. What do you notice in the results?\n",
    "\n",
    "After that, reflect on what you think - beyond a general feeling of \"quality - are possible differences between generating texts with n-grams and generating with LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
