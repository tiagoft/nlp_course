{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca1dfec",
   "metadata": {},
   "source": [
    "# Text classification with a Bag-of-Words approach: a case study for sentiment analysis\n",
    "\n",
    "Classifying texts is the task of assigning a label to each of the elements of a dataset. In text classification, this task is achieved by analyzing and extracting information from text data. One patent example of such is the task of sentiment analysis.\n",
    "\n",
    "Sentiment analysis is the task of identifying if the general sentiment of an excerpt should be considered \"positive\" or \"negative\". Although this is a well known and largely studied problem, it has gained a special importance in the last few years because of the need to monitor social media to find floating sentiments towards particular entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb598a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dda495cd",
   "metadata": {},
   "source": [
    "## Classification by logistic regression\n",
    "\n",
    "One of the ways to perform classification is using Logistic Regression (LR). LR can be seen as a classification counterpart of linear regression. In linear regression, a vector $x$ of continuous features is multiplied by the transpose $w^T$ of a weight vector and has some bias added, yieding:\n",
    "\n",
    "$$\n",
    "z = xw^t + b.\n",
    "$$\n",
    "\n",
    "Note that this is equivalent to stating that $z = b+ \\sum_{i=1}^n x_nw_n$, that is, there is one element in $w$ for each element in $x$ and this element represents the weight given to that element in the final sum.\n",
    "\n",
    "Logistic Regression solves the problem of identifying the class (\"positive\" or \"negative\") that $x$ belongs to. In LR, the final output $y$ is given by $\\sigma(z)$, where:\n",
    "\n",
    "$$\n",
    "y=\\sigma(z)=\\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "This allows interpreting $y$ as the probability that $x$ belongs to the \"positive\" class. Consequently, the weights $w$ and the bias $b$ can be optimized by minimizing the cross entropy loss regarding a labeled dataset.\n",
    "\n",
    "Importantly, Logistic Regression calls for representing each element in the dataset using a vector. One of the solutions for such is the Bag-of-Words approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce5d5d",
   "metadata": {},
   "source": [
    "## Representing texts using Bag-of-words\n",
    "\n",
    "The \"bag\" in bag of words brings the idea that all words from a text are put into a bag and then shuffled. In this case, each element from a text dataset is represented by a vector $x \\in \\mathbb{R}^V$, where $V$ is the number of words in the vocabulary. Thus, $x_i$ corresponds to the $i$-th word in the vocabulary.\n",
    "\n",
    "The simplest way to find $x$ is to assume $x_i$ is $1$ if the corresponding word exists in the text, and $0$ if it does not, which makes each word follow a Bernoulli distribution. Another method is to make $x_i$ equal to the number of times the corresponding word appears in the text. This word count is called \"Term Frequency\" (TF).\n",
    "\n",
    "Another method it to divide TF by the number of documents the corresponding words appears in (that is, the Document Frequency DF). This method is called Term Frequency - Inverse Document Frequency (TFIDF), and yields a vector that informs how much each word is relevant to separate that document from the whole collection.\n",
    "\n",
    "Using BoW and LR is straightforward in Scikit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a528f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85349dd4",
   "metadata": {},
   "source": [
    "## Dataset: IMDB dataset\n",
    "\n",
    "In this study, we use the IMDB dataset because it is a well-known dataset. It is comprised of movie reviews extracted from the IMDB website. Reviews associated with a star rating of 4 our five are considered positive, whereas reviews associate with a star rating of 1 or 2 are considered negative. Reviews with a star rating of 3 are excluded form the dataset. The dataset is pre-divided into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b86e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/plain_text/train-00000-of-00001.parquet\")\n",
    "test_df = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/plain_text/test-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd231c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "eb209267-7052-468e-804d-6102c64687a0",
       "rows": [
        [
         "0",
         "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.",
         "0"
        ],
        [
         "1",
         "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.",
         "0"
        ],
        [
         "2",
         "If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />",
         "0"
        ],
        [
         "3",
         "This film was probably inspired by Godard's Masculin, f√©minin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.",
         "0"
        ],
        [
         "4",
         "Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoked fish hit the U.S. I was too young to get in the theater (although I did manage to sneak into \"Goodbye Columbus\"). Then a screening at a local film museum beckoned - Finally I could see this film, except now I was as old as my parents were when they schlepped to see it!!<br /><br />The ONLY reason this film was not condemned to the anonymous sands of time was because of the obscenity case sparked by its U.S. release. MILLIONS of people flocked to this stinker, thinking they were going to see a sex film...Instead, they got lots of closeups of gnarly, repulsive Swedes, on-street interviews in bland shopping malls, asinie political pretension...and feeble who-cares simulated sex scenes with saggy, pale actors.<br /><br />Cultural icon, holy grail, historic artifact..whatever this thing was, shred it, burn it, then stuff the ashes in a lead box!<br /><br />Elite esthetes still scrape to find value in its boring pseudo revolutionary political spewings..But if it weren't for the censorship scandal, it would have been ignored, then forgotten.<br /><br />Instead, the \"I Am Blank, Blank\" rhythymed title was repeated endlessly for years as a titilation for porno films (I am Curious, Lavender - for gay films, I Am Curious, Black - for blaxploitation films, etc..) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want to see that \"naughty sex film\" that \"revolutionized the film industry\"...<br /><br />Yeesh, avoid like the plague..Or if you MUST see it - rent the video and fast forward to the \"dirty\" parts, just to get it over with.<br /><br />",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a711b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     12500\n",
      "           1       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline.fit(train_df['text'], train_df['label'])\n",
    "y_pred = pipeline.predict(test_df['text'])\n",
    "report = classification_report(test_df['label'], y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc0ab0",
   "metadata": {},
   "source": [
    "As we can see, the results are reasonable. Hence, we can proceed to analyze the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389ae95",
   "metadata": {},
   "source": [
    "## Why did it classify as it did?\n",
    "\n",
    "We can identify which words are typically the most important for classification. For such, we sweep the whole vocabulary and find $y$ corresponding to each of the inputs. The words with largest $y$ are associated with the \"positive\" class, whereas the words with lower $y$ are associated with the \"negative\" class. We can use `predict_proba` to find the values of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89e95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the vocabulary and the classifier from the pipeline\n",
    "vocab = pipeline.named_steps['tfidf'].vocabulary_\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "# Get the feature names (words) from the TfidfVectorizer\n",
    "feature_names = np.array(pipeline.named_steps['tfidf'].get_feature_names_out())\n",
    "# Calculate predict_proba for each word\n",
    "probabilities = pipeline.predict_proba(feature_names)\n",
    "\n",
    "# Create a dataframe with words and their probabilities\n",
    "proba_df = pd.DataFrame(probabilities, index=feature_names, columns=clf.classes_)\n",
    "proba_df.rename(columns={1 : 'positive', 0 : 'negative'}, inplace=True)\n",
    "proba_df = proba_df.sort_values(by='positive', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c0a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "positive",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8a1413c2-86e5-4309-8f9d-ff0861ee8625",
       "rows": [
        [
         "great",
         "0.000714412171704204",
         "0.9992855878282958"
        ],
        [
         "excellent",
         "0.0019730663797155046",
         "0.9980269336202845"
        ],
        [
         "best",
         "0.007317327065133328",
         "0.9926826729348667"
        ],
        [
         "perfect",
         "0.007732065501081076",
         "0.9922679344989189"
        ],
        [
         "wonderful",
         "0.009354596142161387",
         "0.9906454038578386"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.999286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.998027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.992683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.992268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.990645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           negative  positive\n",
       "great      0.000714  0.999286\n",
       "excellent  0.001973  0.998027\n",
       "best       0.007317  0.992683\n",
       "perfect    0.007732  0.992268\n",
       "wonderful  0.009355  0.990645"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f24fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "positive",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6b176d2f-a6c2-444e-af26-8c1f1e6e5b03",
       "rows": [
        [
         "boring",
         "0.9981896537096083",
         "0.0018103462903916875"
        ],
        [
         "waste",
         "0.9985228290591164",
         "0.0014771709408835675"
        ],
        [
         "awful",
         "0.9988536364747915",
         "0.0011463635252084946"
        ],
        [
         "bad",
         "0.9996009578260109",
         "0.0003990421739891149"
        ],
        [
         "worst",
         "0.9999309969032796",
         "6.900309672044561e-05"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boring</th>\n",
       "      <td>0.998190</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>0.998523</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>0.998854</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        negative  positive\n",
       "boring  0.998190  0.001810\n",
       "waste   0.998523  0.001477\n",
       "awful   0.998854  0.001146\n",
       "bad     0.999601  0.000399\n",
       "worst   0.999931  0.000069"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa39b97",
   "metadata": {},
   "source": [
    "As we can see, positive adjectives are associated with the positive class, while negative adjectives are associated with the negative class. This means that our system uses words that are meaningful towards our purpose. This can be seen as evidence that our model is not classifying based on spurious elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e812d5",
   "metadata": {},
   "source": [
    "## How much data do we need?\n",
    "\n",
    "It is common to see phrases such as \"the more data, the better\". However, this is only true to some extent. To find the possible impact of enlarging our dataset, we commonly use a Learning Curve. A Learning Curve is a curve made by changing the size of the training set and then evaluating the accuracy for each training dataset size.\n",
    "\n",
    "The expected behavior is that the accuracy in the test set increases, while the accuracy in the train set decreases, until they asymptotically meet. This \"meeting point\" indicates the maximum amount of data that can lead to better results with the evaluated model, as well as the maximum accuracy for that same model. We can calculate the learning curve as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57b9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [04:48<00:00, 28.86s/it]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import learning_curve\n",
    "\n",
    "def learning_curve(pipeline, train_df, test_df, cv, train_sizes):\n",
    "    from tqdm import tqdm\n",
    "    def get_score(pipeline, train_df, test_df):\n",
    "        X = train_df['text']\n",
    "        y = train_df['label']\n",
    "        pipeline.fit(X, y)\n",
    "        train_score = pipeline.score(X, y)\n",
    "        test_score = pipeline.score(test_df['text'], test_df['label'])\n",
    "        return train_score, test_score\n",
    "    \n",
    "    all_train_scores = []\n",
    "    all_test_scores = []\n",
    "    all_train_sizes = []\n",
    "    for train_size in tqdm(train_sizes):\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        train_sizes = []\n",
    "        for i in range(cv):\n",
    "            # Sample the training data\n",
    "            train_df_ = train_df.sample(frac=train_size, random_state=i)\n",
    "            train_score, test_score = get_score(pipeline, train_df_, test_df)\n",
    "            train_scores.append(train_score)\n",
    "            test_scores.append(test_score)\n",
    "            train_sizes.append(len(train_df_))\n",
    "\n",
    "        all_train_scores.append(train_scores)\n",
    "        all_test_scores.append(test_scores)\n",
    "        all_train_sizes.append(train_sizes)\n",
    "    return np.array(all_train_sizes), np.array(all_train_scores), np.array(all_test_scores)\n",
    "\n",
    "\n",
    "# Generate learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    pipeline, train_df, test_df, cv=5, train_sizes=np.logspace(-2, 0, 10, base=10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a9eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean and standard deviation for training and test scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "train_sizes = np.mean(train_sizes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eead4c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04412753, 0.01505746, 0.00520771, 0.00231387, 0.00297183,\n",
       "       0.00209783, 0.00268345, 0.00145459, 0.00060101, 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a73b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - 2*train_scores_std, train_scores_mean + 2*train_scores_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, test_scores_mean, label='Cross-validation score', color='orange')\n",
    "plt.fill_between(train_sizes, test_scores_mean - 2*test_scores_std, test_scores_mean + 2*test_scores_std, color='orange', alpha=0.2)\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.semilogx()\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ff792",
   "metadata": {},
   "source": [
    "As we can see, if we had around $10^5$ data points (that is, a dataset at least twice as large as ours), our accuracy would probably reach around 92% accuracy. This means that adding more data would present diminishing gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0df96",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this case study, we used a TFIDF+LR pipeline to classify sentiments in the IMDB dataset. As we can see, the words used for classification are meaningful towards writing positive or negative reviews, which indicates the model is well-fitting. Also, the accuracy in the train and test sets is relatively low, which indicates the dataset size is adequate for this problem.\n",
    "\n",
    "Importantly, although the BoW model disregards the order in which words appear, it is able to capture the fact that some words are more likely to be used in particular contexts. Henceforth, this apparent disadvantage is not necessarily harmful to any classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a524659",
   "metadata": {},
   "source": [
    "# Activities\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Remembering (Recall facts and basic concepts)**\n",
    "\n",
    "1.  What is the main task being performed in this case study?\n",
    "2.  What machine learning algorithm is used for the classification task?\n",
    "3.  What technique is used to convert the text reviews into numerical feature vectors?\n",
    "4.  What specific variant of Bag-of-Words is used in the Scikit-learn pipeline? (TF-IDF)\n",
    "5.  What dataset is used for training and testing the model?\n",
    "6.  How were the labels (positive/negative) determined for the reviews in the IMDB dataset?\n",
    "\n",
    "**Understanding (Explain ideas or concepts)**\n",
    "\n",
    "7.  Explain in your own words the core idea behind the Bag-of-Words (BoW) text representation.\n",
    "8.  What is the purpose of the TF-IDF (Term Frequency-Inverse Document Frequency) weighting scheme compared to just counting word occurrences (Term Frequency)?\n",
    "9.  Why is a Scikit-learn `Pipeline` useful for combining the vectorization and classification steps?\n",
    "10. What does the learning curve plotted in the notebook illustrate? What do the two lines (training score and cross-validation score) represent?\n",
    "11. Explain the rationale behind analyzing the `predict_proba` scores for individual words in the vocabulary. What was the author trying to determine?\n",
    "\n",
    "**Applying (Use information in new situations)**\n",
    "\n",
    "12. How would you modify the code cell defining the `pipeline` to use a simple count vectorizer (Term Frequency) instead of TF-IDF?\n",
    "13. If you were given a new, unseen movie review text, what line(s) of code would you use (after the pipeline is trained) to predict whether it's positive or negative?\n",
    "14. Based on the learning curve shown, if you doubled the training data again (to approx. 200,000 reviews), what would you *roughly* expect to happen to the cross-validation accuracy?\n",
    "\n",
    "**Analyzing (Draw connections among ideas, compare/contrast, break down)**\n",
    "\n",
    "15. Analyze the classification report. What does it tell you about the model's ability to correctly identify positive reviews versus negative reviews? Are there significant differences in precision or recall?\n",
    "16. Compare the TF-IDF approach used here with a hypothetical approach that only uses word presence/absence (Bernoulli). What kind of information does TF-IDF capture that the simpler method doesn't?\n",
    "17. What potential limitation of the Bag-of-Words approach is mentioned in the notebook's conclusion? Why might this limitation not be completely detrimental for this specific sentiment analysis task?\n",
    "18. Looking at the learning curve, are the training and cross-validation scores close together or far apart as the training set size increases? What does this gap (or lack thereof) suggest about model variance or bias?\n",
    "\n",
    "**Evaluating (Justify a stand or decision, critique)**\n",
    "\n",
    "19. Evaluate the author's statement: \"the dataset size is adequate for this problem.\" Do you agree or disagree based *only* on the evidence presented in the learning curve? Justify your position.\n",
    "20. Critique the interpretability analysis performed (predicting probability for single words). While insightful, what potential inaccuracies or simplifications does this method introduce compared to how words contribute within a full review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb32a6",
   "metadata": {},
   "source": [
    "## Suggested answers\n",
    "\n",
    "**Remembering**\n",
    "\n",
    "1.  **What is the main task being performed in this case study?**\n",
    "    *   Suggested Answer: The main task is sentiment analysis, which is a type of text classification aimed at identifying whether a piece of text expresses a positive or negative sentiment.\n",
    "\n",
    "2.  **What machine learning algorithm is used for the classification task?**\n",
    "    *   Suggested Answer: Logistic Regression (LR) is used for the classification task.\n",
    "\n",
    "3.  **What technique is used to convert the text reviews into numerical feature vectors?**\n",
    "    *   Suggested Answer: The Bag-of-Words (BoW) approach is used to convert text into numerical vectors.\n",
    "\n",
    "4.  **What specific variant of Bag-of-Words is used in the Scikit-learn pipeline? (TF-IDF)**\n",
    "    *   Suggested Answer: The specific variant used is Term Frequency-Inverse Document Frequency (TF-IDF), implemented via `TfidfVectorizer`.\n",
    "\n",
    "5.  **What dataset is used for training and testing the model?**\n",
    "    *   Suggested Answer: The IMDB movie review dataset is used.\n",
    "\n",
    "6.  **How were the labels (positive/negative) determined for the reviews in the IMDB dataset?**\n",
    "    *   Suggested Answer: Reviews with a star rating of 4 or 5 were considered positive (label 1), and reviews with a rating of 1 or 2 were considered negative (label 0). Reviews with a 3-star rating were excluded.\n",
    "\n",
    "**Understanding**\n",
    "\n",
    "7.  **Explain in your own words the core idea behind the Bag-of-Words (BoW) text representation.**\n",
    "    *   Suggested Answer: BoW treats a text document as an unordered collection (like words thrown into a bag) of its words, disregarding grammar and word order. It represents the document as a numerical vector where each dimension corresponds to a unique word in the entire dataset's vocabulary, and the value in that dimension indicates the presence, count, or weighted frequency (like TF-IDF) of that word in the document.\n",
    "\n",
    "8.  **What is the purpose of the TF-IDF (Term Frequency-Inverse Document Frequency) weighting scheme compared to just counting word occurrences (Term Frequency)?**\n",
    "    *   Suggested Answer: TF-IDF aims to give higher importance to words that are frequent in a specific document but rare across the entire collection of documents. It down-weights words that appear very commonly everywhere (like \"the\", \"a\", \"is\"), which are less informative for distinguishing between documents, and boosts the weight of terms that are more unique or characteristic of a particular document.\n",
    "\n",
    "9.  **Why is a Scikit-learn `Pipeline` useful for combining the vectorization and classification steps?**\n",
    "    *   Suggested Answer: A `Pipeline` is useful because it chains the text vectorization (TF-IDF) and classification (Logistic Regression) steps into a single object. This simplifies the process of training and prediction, ensuring that the same transformations are applied consistently to both training and testing data. It also helps prevent data leakage, as the vectorizer is fitted only on the training data within the cross-validation folds when used with functions like `learning_curve`.\n",
    "\n",
    "10. **What does the learning curve plotted in the notebook illustrate? What do the two lines (training score and cross-validation score) represent?**\n",
    "    *   Suggested Answer: The learning curve illustrates how the model's performance (accuracy) changes as the amount of training data increases. The 'Training score' line shows the model's accuracy on the data it was trained on at each size point. The 'Cross-validation score' line shows the model's average accuracy on unseen data (validation sets from cross-validation) at each training size point, giving a better estimate of how well the model generalizes.\n",
    "\n",
    "11. **Explain the rationale behind analyzing the `predict_proba` scores for individual words in the vocabulary. What was the author trying to determine?**\n",
    "    *   Suggested Answer: The rationale was to interpret the model and understand *which* words it learned to associate most strongly with positive and negative sentiments. By feeding individual words (as documents) into the trained pipeline and getting their predicted probabilities, the author could identify the words that the model considered the strongest indicators of positivity (high probability for class 1) and negativity (high probability for class 0), providing evidence for whether the model learned meaningful features.\n",
    "\n",
    "**Applying**\n",
    "\n",
    "12. **How would you modify the code cell defining the `pipeline` to use a simple count vectorizer (Term Frequency) instead of TF-IDF?**\n",
    "    *   Suggested Answer: You would import `CountVectorizer` from `sklearn.feature_extraction.text` and replace `TfidfVectorizer()` with `CountVectorizer()` in the pipeline definition:\n",
    "        ```python\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        pipeline = Pipeline([\n",
    "            ('cv', CountVectorizer()), # Changed from 'tfidf', TfidfVectorizer()\n",
    "            ('clf', LogisticRegression())\n",
    "        ])\n",
    "        ```\n",
    "\n",
    "13. **If you were given a new, unseen movie review text, what line(s) of code would you use (after the pipeline is trained) to predict whether it's positive or negative?**\n",
    "    *   Suggested Answer: Assuming the trained pipeline object is named `pipeline` and the new review text is stored in a variable `new_review`, you would use:\n",
    "        ```python\n",
    "        prediction = pipeline.predict([new_review])\n",
    "        ```\n",
    "\n",
    "14. **Based on the learning curve shown, if you doubled the training data again (to approx. 200,000 reviews), what would you *roughly* expect to happen to the cross-validation accuracy?**\n",
    "    *   Suggested Answer: The learning curve shows the cross-validation score is starting to plateau around 40,000 samples (the end of the x-axis). Doubling the data again would likely lead to only very small, diminishing gains in accuracy, possibly increasing slightly towards the projected ~92%, but the improvement would be much less significant than the gains seen with smaller dataset sizes.\n",
    "\n",
    "**Analyzing**\n",
    "\n",
    "15. **Analyze the classification report. What does it tell you about the model's ability to correctly identify positive reviews versus negative reviews? Are there significant differences in precision or recall?**\n",
    "    *   Suggested Answer: The classification report shows that the model performs very similarly well on both positive (1) and negative (0) classes. The precision, recall, and F1-scores are all around 0.90 for both classes. There are no significant differences, indicating the model is balanced in its ability to identify both positive and negative reviews correctly.\n",
    "\n",
    "16. **Compare the TF-IDF approach used here with a hypothetical approach that only uses word presence/absence (Bernoulli). What kind of information does TF-IDF capture that the simpler method doesn't?**\n",
    "    *   Suggested Answer: TF-IDF captures two key pieces of information that a simple Bernoulli (presence/absence) approach doesn't: 1) **Term Frequency:** How often a word appears within a single document (a word appearing multiple times might be more important than one appearing once). 2) **Inverse Document Frequency:** How common or rare a word is across all documents (rare words are often more discriminative). By combining these, TF-IDF provides a weighted score reflecting a word's importance, whereas Bernoulli only provides a binary indication of presence.\n",
    "\n",
    "17. **What potential limitation of the Bag-of-Words approach is mentioned in the notebook's conclusion? Why might this limitation not be completely detrimental for this specific sentiment analysis task?**\n",
    "    *   Suggested Answer: The limitation mentioned is that BoW disregards the order in which words appear, losing sequence and grammatical structure information. This might not be completely detrimental for sentiment analysis because the overall sentiment is often strongly conveyed by the presence of specific sentiment-bearing keywords (like \"amazing,\" \"awful,\" \"boring,\" \"great\") regardless of their exact position or the sentence structure. The model can still learn that certain words are highly correlated with positive or negative labels.\n",
    "\n",
    "18. **Looking at the learning curve, are the training and cross-validation scores close together or far apart as the training set size increases? What does this gap (or lack thereof) suggest about model variance or bias?**\n",
    "    *   Suggested Answer: As the training set size increases, the training and cross-validation scores get closer together (converge). A small gap suggests low variance, meaning the model is not overfitting significantly to the training data and generalizes relatively well. If both scores converge at a level below desired performance, it could indicate higher bias (the model might be too simple to capture all the nuances). In this case, they converge around 90%, which is quite good, suggesting a reasonable balance, though the slight remaining gap and upward trend hint there's still a tiny bit of variance or potential for improvement with more data/model complexity.\n",
    "\n",
    "**Evaluating**\n",
    "\n",
    "19. **Evaluate the author's statement: \"the dataset size is adequate for this problem.\" Do you agree or disagree based *only* on the evidence presented in the learning curve? Justify your position.**\n",
    "    *   Suggested Answer: Based purely on the learning curve, the statement is reasonable but perhaps slightly optimistic regarding maximizing performance. The curve shows good performance (~90% accuracy) is achieved with the current data, and the cross-validation score is flattening, indicating diminishing returns from more data. So, it's adequate for achieving *good* results. However, the curve hasn't *completely* flattened, suggesting that more data (as the author estimates up to ~100k) *could* still provide a small improvement (potentially reaching ~92%). Therefore, while adequate for practical purposes and achieving high accuracy, it might not be fully adequate to squeeze out the absolute maximum performance possible with this model architecture.\n",
    "\n",
    "20. **Critique the interpretability analysis performed (predicting probability for single words). While insightful, what potential inaccuracies or simplifications does this method introduce compared to how words contribute within a full review?**\n",
    "    *   Suggested Answer: This method is a simplification because it treats each word in isolation, ignoring the context provided by surrounding words. In reality, word meaning and sentiment contribution can be context-dependent. For example:\n",
    "        *   **Negation:** \"not good\" has the opposite sentiment of \"good.\"\n",
    "        *   **Intensifiers/Mitigators:** \"very bad\" vs. \"a bit bad.\"\n",
    "        *   **Sarcasm:** Context can completely flip the apparent sentiment of words.\n",
    "        *   **Phrases:** Multi-word expressions can have specific meanings (e.g., \"kick the bucket\").\n",
    "    The analysis provides a useful glimpse into which words the model *generally* associates with labels but doesn't reflect how these words interact within the structure of actual reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428408ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
