{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Models: the XX-Century approach\n",
    "\n",
    "So far, we have used probabilistic models to determine the likelihood of finding a word $w$ in any document within the collection $c$, that is: $P(w | c)$. Implicitly, this means that the order of words within a document does not impact its meaning. Metaphorically, it's as if we placed all the words in a big bag, and therefore this type of representation based on the presence or absence of words is called a bag-of-words.\n",
    "\n",
    "The bag-of-words model is effective for many applications but can miss important characteristics of a word: on the one hand, it is unlikely that a text mentioning \"platypuses\" and \"kangaroos\" is not referring to both; on the other hand, the text: \"platypuses are more dangerous than kangaroos\" is very different from \"kangaroos are more dangerous than platypuses\".\n",
    "\n",
    "One way to create models for the order in which words appear in a text is called a generative linguistic model (or generative, depending on the translation you adopt). In this type of model, we estimate the probability of finding the $n$-th word of a sequence based on the previous word, that is:\n",
    "\n",
    "$𝑃(𝑤_𝑛∣𝑤_{𝑛−1})$\n",
    "\n",
    "We can create a small model for the phrase:\n",
    "\n",
    "Pass one, pass two, pass three\n",
    "\n",
    "In this case, our model gives us probabilities like:\n",
    "\n",
    "$P(\\text{pass} | \\text{one}) = 1$\n",
    "\n",
    "$P(\\text{pass} | \\text{two}) = 1$\n",
    "\n",
    "$P(\\text{two} | \\text{pass}) = 1/3$\n",
    "\n",
    "Note that these probabilities are estimated by counting in a training data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: conditional probabilities for next word\n",
    "\n",
    "In the excerpt below:\n",
    "\n",
    "Joana went for a walk with some of her seven dogs on a sunny afternoon, and she met a friend. A person who was there also stopped to talk to them, and some other dogs also stopped to play with the dogs.\n",
    "\n",
    "Calculate:\n",
    "\n",
    "* $P(\\text{afternoon} | \\text{sunny})$\n",
    "* $P(\\text{some} | \\text{with})$\n",
    "* $P(\\text{on} | \\text{dogs})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: estimating a linguistic model\n",
    "\n",
    "There are many libraries that can be used to estimate the conditional probabilities for all words in a text. We are going to build these probabilities from scratch.\n",
    "\n",
    "The piece of code below splits a text into its individual words (we are not concerned with punctuation at this point).\n",
    "\n",
    "Add to the code so that we generate a \"dictionary of dictionaries\", similar to an inverted index. This structure must represent conditional probabilities in the following way:\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "* $P(\\text{dogs} | \\text{with}) = 0.2$\n",
    "* $P(\\text{dogs} | \\text{her}) = 0.3$\n",
    "* $P(\\text{cats} | \\text{her}) = 0.4$\n",
    "\n",
    "the data structure should look like:\n",
    "\n",
    "    {\n",
    "        'with' : { 'dogs' : 0.2 },\n",
    "        'her' : { 'dogs' : 0.3,\n",
    "                  'cats' : 0.4}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NATURAL', 'LANGUAGE', 'PROCESSING', 'NLP', 'IS', 'A', 'SUBFIELD', 'OF', 'LINGUISTICS', 'COMPUTER', 'SCIENCE', 'INFORMATION', 'ENGINEERING', 'AND', 'ARTIFICIAL', 'INTELLIGENCE', 'CONCERNED', 'WITH', 'THE', 'INTERACTIONS', 'BETWEEN', 'COMPUTERS', 'AND', 'HUMAN', 'NATURAL', 'LANGUAGES', 'IN', 'PARTICULAR', 'HOW', 'TO', 'PROGRAM', 'COMPUTERS', 'TO', 'PROCESS', 'AND', 'ANALYZE', 'LARGE', 'AMOUNTS', 'OF', 'NATURAL', 'LANGUAGE', 'DATA', 'CHALLENGES', 'IN', 'NATURAL', 'LANGUAGE', 'PROCESSING', 'FREQUENTLY', 'INVOLVE', 'SPEECH', 'RECOGNITION', 'NATURAL', 'LANGUAGE', 'UNDERSTANDING', 'AND', 'NATURAL', 'LANGUAGE', 'GENERATION', 'NOWADAYS', 'ARTIFICIAL', 'INTELLIGENCE', 'IS', 'A', 'HIGHLY', 'TRENDING', 'TECHNOLOGY', 'AND', 'IS', 'GAINING', 'POPULARITY', 'AMONG', 'NLP', 'DEVELOPERS', 'ALTHOUGH', 'ARTIFICIAL', 'INTELLIGENCE', 'IS', 'A', 'MARVELOUS', 'TECHNOLOGY', 'AND', 'HAS', 'WONDERFUL', 'RESULTS', 'IT', 'IS', 'STILL', 'A', 'DEVELOPING', 'TECHNOLOGY', 'AND', 'ITS', 'ETHICAL', 'USE', 'IS', 'A', 'MAJOR', 'CONCERN']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence\n",
    "concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze\n",
    "large amounts of natural language data.\n",
    "Challenges in natural language processing frequently involve speech recognition, natural language understanding,\n",
    "and natural language generation. Nowadays, Artificial Intelligence is a highly trending technology and is gaining popularity among NLP developers.\n",
    "Although Artificial Intelligence is a marvelous technology and has wonderful results, it is still a developing technology and its ethical use is a major concern.\n",
    "\"\"\"\n",
    "\n",
    "words = re.findall(r\"\\b\\w+\\b\", text.upper())\n",
    "print(words)\n",
    "\n",
    "conditional_probabilities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Use the code below to test your solution\n",
    "import joblib\n",
    "loaded_conditional_probabilities = joblib.load(\"conditional_probabilities.joblib\")\n",
    "print (conditional_probabilities == loaded_conditional_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: suggest a next word\n",
    "\n",
    "Based on the model estimated in the previous exercise, program a function that takes a word and returns a possible next word. If the base word is not part of the model's vocabulary, it should return a random word from the vocabulary. Use the `np.random.choice` functionality to make choices with predefined probabilities, as shown below. Remember that you should use the probabilities calculated by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.random.choice(['one', 'two', 'three'], p=[0.5, 0.2, 0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: make a text generator\n",
    "\n",
    "Use the functionality you implemented above to suggest next words, and then incorporate them into your text. For example:\n",
    "\n",
    "1. Start with \"artificial intelligence is\"\n",
    "1. Suggest word \"a\"\n",
    "1. Incorporate \"a\" into the original sentence, so that we have: \"artificial intelligence is a\"\n",
    "1. Suggest next word based on \"artificial intelligence is a\"\n",
    "1. Keep going!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model : dict, starting_string : str, num_words : int) -> str:\n",
    "    text = starting_string\n",
    "    # Generate words based on your model (model should be the conditional probabilities!)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: use n-grams\n",
    "\n",
    "By now, you might have noticed that using one single word in the past to predict the next word feels wrong. This is because we choose words based on a long-term context - and using a single word is a large oversimplification on this.\n",
    "\n",
    "A possible solution is to change our original equation $𝑃(𝑤_𝑛∣𝑤_{𝑛−1})$ to a less naive one in which the probability of a word is calculated based on $L$ previous words ($L$ stands for \"context length\"): $𝑃(𝑤_𝑛∣𝑤_{𝑛−1}, w_{n-2}, \\cdots, w_{n-L})$ . For such, we will need to use n-grams.\n",
    "\n",
    "N-grams are simply sequences of N words that appear in the text. For example, in \"these are nice n-grams\", for n=2, we have the n-grams: \"these are\", \"are nice\", \"nice n-grams\". Note that now we can calculate $P(\\text{nice}|\\text{these are}).\n",
    "\n",
    "Based on the code below, change your code to find conditional probabilities so now we have a data structure that models $𝑃(𝑤_𝑛∣𝑤_{𝑛−1}, w_{n-2}, \\cdots, w_{n-L})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(words : list, L : int) -> list:\n",
    "    ngrams = [tuple(words[i:i+L]) for i in range(len(words)-L)]\n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: a fallback strategy\n",
    "\n",
    "Also, by now, you probably found out that larger n-grams become more and more uncommon. This is so true that finding two texts that contain n-grams with a context $L$ larger than around 10 can be used as basis to flag copy-paste plagiarism. Hence, with larger n-grams, we will probably fall into situations in which we don't have information on how to proceed.\n",
    "\n",
    "On the other hand, we might like larger context lengths because they can make our texts more cohesive.\n",
    "\n",
    "How to deal with that?\n",
    "\n",
    "One possibility is to have a weighting strategy in which the probabilities for models that consider different n-gram lengths are combined. However, the optimal combination could be hard to obtain.\n",
    "\n",
    "Another possibility is to use a fallback strategy: we try a model with context $L$. If it fails to find the n-gram, then we proceed to a model with context $L-1$, and so on.\n",
    "\n",
    "Implement a system with a fallback strategy and train/test it in our original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: generation techniques\n",
    "\n",
    "At this point, we generate the \"next word\" in a sequence by sampling from a distribution measured from data. We can make some tweaks here to make our generated words more interesting.\n",
    "\n",
    "### Temperature\n",
    "\n",
    "One possibility is to use a parameter called *temperature*. The temperature parameter (often referred to as $\\tau$) is inspired in annealing processes. In this process, electrons in materias with high temperature jump more often, thus they can be found in a probability cloud with larger variance.\n",
    "\n",
    "When we use temperature, we sample from a distribution $P_z$ calculated by:\n",
    "\n",
    "$$P_z( A | B) =  \\frac{P( A | B) ^ {e^{-\\tau}}}{\\sum{P( A | B) ^ {e^{-\\tau}}}} $$\n",
    "\n",
    "Note that, in this equation, a high temperature $(\\tau \\rightarrow \\infty)$ leads $P_z(A|B)$ to become a uniform distribution, whereas low (negative) values make the distribution more spiky. \n",
    "\n",
    "Also, note that there are many formulations for temperature. I like this one because $\\tau=0$ implies in $P_z(A|B) = P(A|B)$, so we have an anchor point. Check the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.4 0.1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def apply_temperature(P, tau):\n",
    "    z =  P**(np.exp(-tau))\n",
    "    return z / np.sum(z)\n",
    "P = np.array([0.5, 0.4, 0.1])\n",
    "print(apply_temperature(P, 0))\n",
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.bar(range(3), apply_temperature(P, 0))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = 0')\n",
    "plt.subplot(1,3,3)\n",
    "plt.bar(range(3), apply_temperature(P, 2))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = 2')\n",
    "plt.subplot(1,3,1)\n",
    "plt.bar(range(3), apply_temperature(P, -2))\n",
    "plt.ylim(0,1)\n",
    "plt.title('$\\\\tau$ = -2')\n",
    "plt.suptitle('Higher temperature makes the distribution closer to uniform!')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K\n",
    "\n",
    "Top-K generation is another interesting technique that essentially means we select the top $K$ most likely words from the distribution and then sample from them using uniform probabilities. The choice of $K$ impacts the level of randomness in the generation, and this technique can avoid large deviations from a particular trail of thought.\n",
    "\n",
    "### Implementing temperature or top-k\n",
    "\n",
    "Implement either temperature or top-k generation in your word generation function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: reading from real data\n",
    "\n",
    "The code below loads The Complete Works of Shakespeare from Project Guttemberg. Use this text to train your model and check if you can generate some shakespeare-like texts using your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "def load_shakespeare():\n",
    "    \"\"\"Getting Shakespeare text from Project Gutenberg \"\"\"\n",
    "\n",
    "    def download_file():\n",
    "        url = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            raise FileNotFoundError(\"Failed to download file.\")\n",
    "        text = response.content.decode('utf-8')\n",
    "        start_index = text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
    "        end_index = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
    "        if start_index == -1 or end_index == -1:\n",
    "            raise ValueError(\"Failed to find the start \"\n",
    "                             \"or end of the book in the text.\")\n",
    "        text = text[start_index:end_index]\n",
    "        return text\n",
    "\n",
    "    filepath_shakespeare = Path(\"shakespeare.txt\")\n",
    "\n",
    "    if filepath_shakespeare.exists():\n",
    "        print(\"File already exists. Skipping download...\")\n",
    "        with open(filepath_shakespeare, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    else:\n",
    "        print(\"Downloading file...\")\n",
    "        text = download_file()\n",
    "        with open(filepath_shakespeare, 'w', encoding='utf-8') as file:\n",
    "            file.write(text)\n",
    "        print(\"Download complete and text should be in 'shakespeare.txt' file.\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Temperature and LLMs.\n",
    "\n",
    "Well here comes my usual text about \"everything is LLMs nowadays\". Let's try temperature experiments with LLMs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 (low temp):  In generative models, temperature controls the randomness of the output.  A temperature of 1.0 means the model samples directly from its learned probability distribution.  Higher temperatures (e.g., 1.5) increase randomness, leading to more creative, surprising, and potentially nonsensical outputs.  The model becomes more likely to sample less probable tokens, exploring the less-visited parts of its probability landscape.  Lower temperatures (e.g., 0.5) decrease randomness, making the output more focused, deterministic, and likely to select the most probable tokens.  This results in more coherent but potentially less imaginative results.  Essentially, temperature acts as a dial controlling the balance between creativity and coherence in the generated text or other data.\n",
      "\n",
      "Response 2 (low temp):  In generative models, temperature controls the randomness of the output.  A temperature of 1.0 means the model samples directly from its learned probability distribution.  Higher temperatures (e.g., 1.5) increase randomness, leading to more creative, unexpected, and potentially nonsensical outputs.  The model becomes more likely to sample from less probable tokens, exploring the less-likely parts of its learned distribution.  Lower temperatures (e.g., 0.5) decrease randomness, resulting in more focused, deterministic, and often more repetitive outputs. The model favors high-probability tokens, sticking closer to the most likely sequences.  Essentially, temperature acts as a dial controlling the balance between creativity and coherence in the generated text or other data.\n",
      "\n",
      "Response 3 (high temp):  Temperature in generative models controls the randomness of the model's output.  A lower temperature (e.g., 0.2) makes the model more deterministic, favoring the most likely next tokens or features. This leads to sharper, more focused, and often more coherent outputs, but can also result in repetitive or predictable results.\n",
      "\n",
      "Higher temperatures (e.g., 1.0 or above) increase randomness, leading to more diverse and surprising outputs.  The model becomes less certain about its predictions, exploring a wider range of possibilities. While this fosters creativity, it may also result in nonsensical or incoherent text or images.\n",
      "\n",
      "Essentially, temperature acts as a knob to balance creativity and coherence in the generation process.  The optimal temperature depends heavily on the specific model and the desired output characteristics.\n",
      "\n",
      "Response 4 (high temp):  Temperature in generative models controls the randomness of the output.  A temperature of 1.0 means the model samples from its probability distribution directly, producing the most likely outputs.  Lower temperatures (e.g., 0.2) make the distribution sharper, concentrating probability on the highest-likelihood outputs resulting in more focused, deterministic samples. This often leads to more coherent but potentially less diverse results.  Higher temperatures (e.g., 2.0) flatten the distribution, increasing the probability of less likely outputs. This produces more surprising, creative, and diverse but potentially incoherent or nonsensical samples.  Essentially, temperature acts as a knob controlling the balance between quality and creativity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "#GEMINI_API_KEY = # Go to https://aistudio.google.com/ to get a key. DO NOT commit your key to the repository!\n",
    "\n",
    "# Start the use of the API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Make our prompt here\n",
    "prompt = f\"Explain how temperature works in generative models in less than 200 words.\"\n",
    "generation_config_low_temp = genai.GenerationConfig(\n",
    "    max_output_tokens=500,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "generation_config_high_temp = genai.GenerationConfig(\n",
    "    max_output_tokens=500,\n",
    "    temperature=2.0,\n",
    ")\n",
    "\n",
    "# Use our prompt four times\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=generation_config_low_temp)\n",
    "print(\"Response 1 (low temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=generation_config_low_temp)\n",
    "print(\"Response 2 (low temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=generation_config_high_temp)\n",
    "print(\"Response 3 (high temp): \", response.text)\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=generation_config_high_temp)\n",
    "print(\"Response 4 (high temp): \", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we know how to configure temperature with LLMs - they are simply a parameter in the call!\n",
    "\n",
    "Go on your own now. Let's try some ideas:\n",
    "\n",
    "1. Ask the LLM to generate a paragraph in which a shakespearean hero finds out his beloved one is married to another man.\n",
    "1. Intentionally describe the character in a bit more detail\n",
    "1. Insert the initial part of Shakespeare's Complete Works as part of the prompt, so that the system copies Shakespeare's style.\n",
    "1. Adjust the temperature parameter in the cases above. What do you notice in the results?\n",
    "\n",
    "After that, reflect on what you think - beyond a general feeling of \"quality - are possible differences between generating texts with n-grams and generating with LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
